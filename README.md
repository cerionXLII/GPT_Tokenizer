# GPT_Tokenizer
This is a simple GPT Tokenizer that uses byte pair encodings. This can then be used together with a LLM to decode tokens to strings and encode strings into tokens.
